{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "70ca9e162c4847caa440eb24d837567b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6164,
    "execution_start": 1669065926905,
    "source_hash": "41699a00",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow_hub) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /shared-libs/python3.7/py/lib/python3.7/site-packages (from tensorflow_hub) (1.21.6)\n",
      "Installing collected packages: tensorflow_hub\n",
      "Successfully installed tensorflow_hub-0.12.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow Hub\n",
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f59f5",
   "metadata": {},
   "source": [
    "\n",
    "## Scientific Explanation of Image Processing\n",
    "\n",
    "This notebook leverages TensorFlow and TensorFlow Hub to perform image processing tasks, particularly focusing on enhancing image resolution. The process involves:\n",
    "\n",
    "1. **Preprocessing**: Adjusting image size and format to meet model requirements.\n",
    "2. **Model Application**: Utilizing pre-trained models from TensorFlow Hub to enhance or modify images.\n",
    "3. **Post-processing**: Saving the enhanced images and performing any final adjustments.\n",
    "\n",
    "These steps are crucial for tasks such as super-resolution, where the goal is to increase the resolution of input images using deep learning techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "2efb903acf21404ea299da819ad8f9af",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5631,
    "execution_start": 1669065932044,
    "source_hash": "f9b6afff",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 21:25:32.104755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 21:25:32.313812: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-21 21:25:32.313846: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-21 21:25:32.345215: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-21 21:25:34.235361: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-21 21:25:34.235465: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-21 21:25:34.235479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "from PIL import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "ec969f4c690f4184ab67602282cb6b79",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1669065937685,
    "source_hash": "2a4ebb41",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to save images\n",
    "# Define a function to preprocess images to make them model-ready\n",
    "def preprocess_image(image_path):\n",
    "  \"\"\" Loads image from path and preprocesses to make it model ready\n",
    "      Args:\n",
    "        image_path: Path to the image file\n",
    "  \"\"\"\n",
    "  hr_image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "  # If PNG, remove the alpha channel. The model only supports\n",
    "  # images with 3 color channels.\n",
    "  if hr_image.shape[-1] == 4:\n",
    "    hr_image = hr_image[...,:-1]\n",
    "  hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 4) * 4\n",
    "  hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n",
    "  hr_image = tf.cast(hr_image, tf.float32)\n",
    "  return tf.expand_dims(hr_image, 0)\n",
    "\n",
    "def save_image(image, filename):\n",
    "  \"\"\"\n",
    "    Saves unscaled Tensor Images.\n",
    "    Args:\n",
    "      image: 3D image tensor. [height, width, channels]\n",
    "      filename: Name of the file to save.\n",
    "  \"\"\"\n",
    "  if not isinstance(image, Image.Image):\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "  image.save(\"%s.jpg\" % filename)\n",
    "  print(\"Saved as %s.jpg\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "7616565307b44b32bd12ffda843a3617",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6387,
    "execution_start": 1669065937693,
    "source_hash": "d66993c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://tfhub.dev/captain-pool/esrgan-tf2/1, Total size: 20.60MB\n",
      "\n",
      "2022-11-21 21:25:38.449263: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-21 21:25:38.449323: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-21 21:25:38.449350: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-0449f7a0-0404-4608-a8fb-4d9687970365): /proc/driver/nvidia/version does not exist\n",
      "2022-11-21 21:25:38.449679: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Declaring Constants\n",
    "IMAGE_PATH = \"/work/temp.jpg\"\n",
    "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\"\n",
    "model = hub.load(SAVED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "be9882048e6f4c8f97c29d41dc02cf57",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5491,
    "execution_start": 1669065944056,
    "source_hash": "23013d94",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting anvil-uplink\n",
      "  Downloading anvil_uplink-0.4.1-py2.py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting argparse\n",
      "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting ws4py\n",
      "  Downloading ws4py-0.5.1.tar.gz (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /shared-libs/python3.7/py-core/lib/python3.7/site-packages (from anvil-uplink) (1.16.0)\n",
      "Requirement already satisfied: future in /shared-libs/python3.7/py/lib/python3.7/site-packages (from anvil-uplink) (0.18.2)\n",
      "Building wheels for collected packages: ws4py\n",
      "  Building wheel for ws4py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ws4py: filename=ws4py-0.5.1-py3-none-any.whl size=45215 sha256=dd0cd695077228089958db52ae54084cb85c8fb7f1b9e702d10b6f69535b6224\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/ea/7d/3410aa0aa0e4402ead9a7a97ab2214804887e0f5c2b76f0c96\n",
      "Successfully built ws4py\n",
      "Installing collected packages: ws4py, argparse, anvil-uplink\n",
      "Successfully installed anvil-uplink-0.4.1 argparse-1.4.0 ws4py-0.5.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install anvil-uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "9e86a19e83514b3d972ff68328106a75",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 403,
    "execution_start": 1669065949390,
    "source_hash": "fc8a0304",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import anvil.server\n",
    "import io\n",
    "\n",
    "anvil.server.connect(\"67FM7PLGW7MWMUJRPBHGN4XM-CZ27UJXWRRE4WPXP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "1a2eda3e1238470fa1571125d74353c9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24277192,
    "execution_start": 1669065949795,
    "source_hash": "f51d18dd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import anvil.server\n",
    "import anvil.media\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "anvil.server.connect(\"67FM7PLGW7MWMUJRPBHGN4XM-CZ27UJXWRRE4WPXP\")\n",
    "\n",
    "def write_a_file(file):\n",
    "  with open('temp.jpg','wb') as f:\n",
    "    f.write(file)\n",
    "\n",
    "@anvil.server.callable\n",
    "def super(file):\n",
    "  print(\"Call\")\n",
    "  with anvil.media.TempFile(file) as f:\n",
    "    img = load_img(f)\n",
    "    MAX_SIZE = (96, 96)\n",
    "    img.thumbnail(MAX_SIZE)\n",
    "    img_array = img_to_array(img)\n",
    "    save_img('temp.jpg', img_array)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    IMAGE_PATH = \"/work/temp.jpg\"\n",
    "    hr_image = preprocess_image(IMAGE_PATH)\n",
    "    fake_image = model(hr_image)\n",
    "    fake_image = tf.squeeze(fake_image)\n",
    "    save_image(tf.squeeze(fake_image), filename=\"Super Resolution\")\n",
    "\n",
    "\n",
    "    super_img = Image.open(\"/work/Super Resolution.jpg\")\n",
    "    print(type(img), \"IMG Loaded\")\n",
    "    \n",
    "    super_img = Image.open(\"Super Resolution.jpg\")\n",
    "    name='super_img'\n",
    "    bs = io.BytesIO()\n",
    "    super_img.save(bs, format=\"JPEG\")\n",
    "\n",
    "  return anvil.BlobMedia(\"image/jpg\", bs.getvalue(), name=name)\n",
    "  \n",
    "\n",
    "\n",
    "anvil.server.wait_forever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=0449f7a0-0404-4608-a8fb-4d9687970365' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e75dfd90fc054591ad09b7757d7ea36b"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
